{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "# you have to download this using\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Done. 2195884  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove = loadGloveModel(\"glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funstion that takes in the words and gives them back with the label, also removes the special characters\n",
    "def labeling(word):\n",
    "    one = \"*\"\n",
    "    two = \"!\"\n",
    "    \n",
    "    # remove special characters\n",
    "    ret = re.sub('[^A-Za-z0-9]+', '',word)\n",
    "    \n",
    "    if one in word:\n",
    "        return ret, 1\n",
    "    elif two in word:\n",
    "        return ret, 2\n",
    "    else:\n",
    "        return ret, 3\n",
    "    \n",
    "# this function uses the wordnet and expands the words using synonyms \n",
    "# this exapnsion is capped at the given iteration n\n",
    "# takes in a set words\n",
    "def expand(words, n=5):\n",
    "    expanded = set()\n",
    "    \n",
    "    for x in range(n):\n",
    "        if len(words) == 0:\n",
    "            break\n",
    "        w = words.pop()\n",
    "        expanded.add(w)\n",
    "    \n",
    "        for syn in wordnet.synsets(w): \n",
    "            for l in syn.lemmas(): \n",
    "                words.add(l.name()) \n",
    "\n",
    "    return list(expanded|words)\n",
    "\n",
    "def getSimilar(words, emb, n=15):\n",
    "    return [x[0] for x in emb.most_similar(positive=words, topn=n)]\n",
    "\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Model\")\n",
    "    model = {}\n",
    "    with open(gloveFile,'r') as f:\n",
    "        for line in f:\n",
    "            splitLine = line.split()\n",
    "            \n",
    "            word = splitLine[0]\n",
    "            # needed for special cases such as \". . .\" which we will not have in this\n",
    "            try:\n",
    "                float(splitLine[1])\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "            model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "# get embedded representations of the words\n",
    "def getInputData(words, emb):\n",
    "    \n",
    "    out = []\n",
    "    for word in words:\n",
    "        # if embedding not found\n",
    "        if word not in emb:\n",
    "            if word.lower() not in emb:\n",
    "                # unknown word given the token \"UNK\"\n",
    "                out.append(emb['UNK'])\n",
    "            else:\n",
    "                out.append(emb[word.lower()])\n",
    "        else:\n",
    "            out.append(emb[word])\n",
    "        \n",
    "    return np.array(out)\n",
    "\n",
    "# get one hot encoding of labels\n",
    "def getOneHot(inlabel):\n",
    "    enc = OneHotEncoder()\n",
    "    out = enc.fit_transform(inlabel.reshape(-1,1)).toarray()\n",
    "    return out\n",
    "\n",
    "# print the asner from the Instalearn\n",
    "def answer(pred, orig, indata):\n",
    "    red = ' \\033[0;31;48m'\n",
    "    blue = ' \\033[0;34;48m'\n",
    "    norm = ' \\033[0;39;48m'\n",
    "    x = 0\n",
    "    ans = ''\n",
    "    for w in orig:\n",
    "        if re.sub('[^A-Za-z0-9]+', '',w) in indata:\n",
    "            if pred[x] == 3:\n",
    "                ans = ans + norm + w\n",
    "            elif pred[x] == 1:\n",
    "                ans = ans + red + indata[x]\n",
    "            else:\n",
    "                ans = ans + blue + indata[x]\n",
    "            x+=1\n",
    "    ans = ans + norm\n",
    "    return ans[1:]\n",
    "\n",
    "\n",
    "def shuffle(words, labels):\n",
    "    # getting curent state so shuffle is the same for both arrays\n",
    "    curState = np.random.get_state()\n",
    "    np.random.shuffle(words)\n",
    "    \n",
    "    # setting the state\n",
    "    np.random.set_state(curState)\n",
    "    np.random.shuffle(labels)\n",
    "    \n",
    "    return words, labels\n",
    "\n",
    "# function for computing basic metric, takes in actual words and predicted words as input\n",
    "def metric(w, p, mode):\n",
    "    tp = 0\n",
    "    for word in p:\n",
    "        if word in w:\n",
    "            tp+=1\n",
    "    precision = tp/len(w)\n",
    "    recall = tp/len(p)\n",
    "    print(\"\\n\"+mode)\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1-Score: ', (2*precision*recall)/(precision+recall))\n",
    "    \n",
    "    \n",
    "    \n",
    "# fucntion for evaluating labeled input\n",
    "def evaluate(sentence, model, emb):\n",
    "    raw = sentence.split(\" \")\n",
    "    etr = []\n",
    "    elb = []\n",
    "    for words in raw:\n",
    "        t , l = labeling(words)\n",
    "        etr.append(t)\n",
    "        elb.append(l)\n",
    "    etr = np.array(etr)\n",
    "    \n",
    "    exp1 = list(etr[[i == 1 for i in elb]])\n",
    "    exp2 = list(etr[[i == 2 for i in elb]])\n",
    "    \n",
    "    ans = model.predict(getInputData(etr, emb))\n",
    "    \n",
    "    print(answer(ans, etr, etr))\n",
    "    \n",
    "    print(\"\\n Evaluation Metrics\")\n",
    "    w1 = list(etr[[i == 1 for i in (ans)]])\n",
    "    w2 = list(etr[[i == 2 for i in (ans)]])\n",
    "    # print('Total Words: ', len(trainX))\n",
    "    print('Total *Words: ', len(w1), w1)\n",
    "    print('Actual *Words: ', exp1)\n",
    "    print('Total !Words: ', len(w2), w2)\n",
    "    print('Actual !Words: ', exp2)\n",
    "\n",
    "    metric(exp1+(exp2), w1+(w2), \"Overall\")\n",
    "    metric(exp2, w2, \"!\")\n",
    "    metric(exp1, w1, \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I lived in *Munich last summer. *Germany has a relaxing, slow summer lifestyle. One night, I got food poisoning and couldn't find !Tylenol to make the pain go away, they insisted I take !aspirin instead.\n"
     ]
    }
   ],
   "source": [
    "rawText = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I used to drive around with my !dogs in my *Ferrari. But then I got a !cat and bought a *Porsche for her.\n"
     ]
    }
   ],
   "source": [
    "rawText = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = rawText.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = []\n",
    "lb = []\n",
    "\n",
    "# getting the words and the labels\n",
    "for words in tk:\n",
    "    t , l = labeling(words)\n",
    "    tr.append(t)\n",
    "    lb.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.array(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the important words to artifically augment data size\n",
    "exp1 = list(tr[[i == 1 for i in lb]])\n",
    "exp2 = list(tr[[i == 2 for i in lb]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(tr[[i == 3 for i in lb]])\n",
    "labels = [3]*len(data)\n",
    "\n",
    "# assert len(data) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded from wordnet\n",
    "exp = expand(set(exp1), 10)\n",
    "data += exp\n",
    "labels += [1]*len(exp)\n",
    "\n",
    "# expanded from Word2Vec\n",
    "exp = getSimilar((exp1), model, 15)\n",
    "data += exp\n",
    "labels += [1]*len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded from wordnet\n",
    "exp = expand(set(exp2), 10)\n",
    "data += exp\n",
    "labels += [2]*len(exp)\n",
    "\n",
    "# expanded from Word2Vec\\\n",
    "exp = getSimilar((exp2), model, 15)\n",
    "data += exp\n",
    "labels += [2]*len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, label = shuffle(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ohlabel = getOneHot(np.array(label))\n",
    "trainX = getInputData(train, glove)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 300) (250,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape,label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n",
      "Total Words:  23\n",
      "Total *Words:  2\n",
      "Total !Words:  2\n"
     ]
    }
   ],
   "source": [
    "# Model Train Data\n",
    "print(\"Original Data\")\n",
    "print('Total Words: ', len(tr))\n",
    "print('Total *Words: ', len(exp1))\n",
    "print('Total !Words: ', len(exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Data\n",
      "Total Words:  250\n",
      "Total *Words:  17\n",
      "Total !Words:  214\n"
     ]
    }
   ],
   "source": [
    "print(\"Augmented Data\")\n",
    "print('Total Words: ', len(trainX))\n",
    "print('Total *Words: ', len(trainX[[i == 1 for i in (label)]]))\n",
    "print('Total !Words: ', len(trainX[[i == 2 for i in (label)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(250, 500, 150, 100, 30),\n",
       "       learning_rate='adaptive', learning_rate_init=0.0001, max_iter=1500,\n",
       "       momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "       power_t=0.5, random_state=110, shuffle=True, solver='sgd',\n",
       "       tol=1e-12, validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using simple perceptron because Occams Razor\n",
    "mlf = MLPClassifier(hidden_layer_sizes=(250,500,150, 100, 30), activation='tanh',\n",
    "                    max_iter=1500, alpha=0.0001,learning_rate=\"adaptive\",\n",
    "                    learning_rate_init=0.0001,solver='sgd', verbose=False,  \n",
    "                    random_state=110,tol=0.000000000001, nesterovs_momentum=True, warm_start=True)\n",
    "\n",
    "mlf.fit(trainX, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39;48mI \u001b[0;39;48mused \u001b[0;39;48mto \u001b[0;39;48mdrive \u001b[0;39;48maround \u001b[0;39;48mwith \u001b[0;39;48mmy \u001b[0;34;48mdogs \u001b[0;39;48min \u001b[0;39;48mmy \u001b[0;31;48mFerrari \u001b[0;39;48mBut \u001b[0;39;48mthen \u001b[0;39;48mI \u001b[0;39;48mgot \u001b[0;39;48ma \u001b[0;34;48mcat \u001b[0;39;48mand \u001b[0;39;48mbought \u001b[0;39;48ma \u001b[0;31;48mPorsche \u001b[0;39;48mfor \u001b[0;39;48mher \u001b[0;39;48m\n",
      "\n",
      " Evaluation Metrics\n",
      "Total *Words:  2 ['Ferrari', 'Porsche']\n",
      "Actual *Words:  ['Ferrari', 'Porsche']\n",
      "Total !Words:  2 ['dogs', 'cat']\n",
      "Actual !Words:  ['dogs', 'cat']\n",
      "\n",
      "Overall\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n",
      "\n",
      "!\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n",
      "\n",
      "*\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Self Evaluation\n",
    "evaluate(rawText, mlf, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I crashed my *Mustang but my !parrot and !snake were not in the car.\n",
      "\u001b[0;39;48mI \u001b[0;39;48mcrashed \u001b[0;39;48mmy \u001b[0;31;48mMustang \u001b[0;39;48mbut \u001b[0;39;48mmy \u001b[0;34;48mparrot \u001b[0;39;48mand \u001b[0;34;48msnake \u001b[0;39;48mwere \u001b[0;39;48mnot \u001b[0;39;48min \u001b[0;39;48mthe \u001b[0;34;48mcar \u001b[0;39;48m\n",
      "\n",
      " Evaluation Metrics\n",
      "Total *Words:  1 ['Mustang']\n",
      "Actual *Words:  ['Mustang']\n",
      "Total !Words:  3 ['parrot', 'snake', 'car']\n",
      "Actual !Words:  ['parrot', 'snake']\n",
      "\n",
      "Overall\n",
      "Precision:  1.0\n",
      "Recall:  0.75\n",
      "F1-Score:  0.8571428571428571\n",
      "\n",
      "!\n",
      "Precision:  1.0\n",
      "Recall:  0.6666666666666666\n",
      "F1-Score:  0.8\n",
      "\n",
      "*\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with tags\n",
    "evalInput = input()\n",
    "evaluate(evalInput, mlf, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39;48mI \u001b[0;39;48mused \u001b[0;39;48mto \u001b[0;39;48msell \u001b[0;34;48mVicodin \u001b[0;39;48min \u001b[0;31;48mTurkey \u001b[0;39;48m\n",
      "Evaluation Metrics\n",
      "Total *Words:  1 ['Turkey']\n",
      "Actual *Words:  ['Turkey']\n",
      "Total !Words:  1 ['Vicodin']\n",
      "Actual !Words:  ['Vicodin']\n",
      "\n",
      "Overall\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n",
      "\n",
      "!\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n",
      "\n",
      "*\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1-Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# was done for the given example the sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I lived in Paris last year, France was experiencing a recession. The night life was too fun, I developed an addiction to Adderall and Ritalin.\n"
     ]
    }
   ],
   "source": [
    "testInput = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = testInput.split(\" \")\n",
    "test = []\n",
    "\n",
    "\n",
    "# getting the words and the labels\n",
    "for words in tst:\n",
    "    t , l = labeling(words)\n",
    "    test.append(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = getInputData(test, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39;48mWhen \u001b[0;39;48mI \u001b[0;39;48mlived \u001b[0;39;48min \u001b[0;31;48mParis \u001b[0;39;48mlast \u001b[0;39;48myear, \u001b[0;31;48mFrance \u001b[0;39;48mwas \u001b[0;39;48mexperiencing \u001b[0;39;48ma \u001b[0;39;48mrecession. \u001b[0;39;48mThe \u001b[0;39;48mnight \u001b[0;39;48mlife \u001b[0;39;48mwas \u001b[0;39;48mtoo \u001b[0;39;48mfun, \u001b[0;39;48mI \u001b[0;39;48mdeveloped \u001b[0;39;48man \u001b[0;39;48maddiction \u001b[0;39;48mto \u001b[0;34;48mAdderall \u001b[0;39;48mand \u001b[0;34;48mRitalin\n"
     ]
    }
   ],
   "source": [
    "ans = mlf.predict(teste)\n",
    "\n",
    "print(answer(ans, tst, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
